{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOO8oCAzE9DI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GoIQuGWmK1m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ZLiIEjXr2FVo",
        "outputId": "249d724b-61fd-4526-ec05-a9efcc82e5e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bc1afc40-16a6-42b3-ace2-c8b0637e7eb0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bc1afc40-16a6-42b3-ace2-c8b0637e7eb0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1.csv to 1.csv\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install xgboost\n",
        "\n",
        "# Upload the dataset manually\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the uploaded file (assuming it's '1.csv')\n",
        "import pandas as pd\n",
        "data = pd.read_csv('1.csv', encoding='latin')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xoPfVZzWFKsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, matthews_corrcoef\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Preprocess dataset\n",
        "data.rename(columns={'v1': 'Class', 'v2': 'Text'}, inplace=True)\n",
        "data['numClass'] = data['Class'].map({'ham': 0, 'spam': 1})\n",
        "data['Count'] = 0\n",
        "for i in np.arange(0, len(data.Text)):\n",
        "    data.loc[i, 'Count'] = len(data.loc[i, 'Text'])\n",
        "\n",
        "# Exploratory analysis\n",
        "print(\"Unique values in the Class set: \", data.Class.unique())\n",
        "ham = data[data.numClass == 0]\n",
        "print(\"Number of ham messages in data set:\", ham['Class'].count())\n",
        "spam = data[data.numClass == 1]\n",
        "print(\"Number of spam messages in data set:\", spam['Class'].count())\n",
        "\n",
        "# Text vectorization with TF-IDF\n",
        "stopset = list(stopwords.words(\"english\"))\n",
        "vectorizer = TfidfVectorizer(stop_words=stopset)\n",
        "X = vectorizer.fit_transform(data.Text)\n",
        "y = data.numClass\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Shape of feature matrix:\", X.shape)\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-iqOlEa2Mtl",
        "outputId": "8928e63b-47b5-4595-e591-b7b091320b1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in the Class set:  ['ham' 'spam']\n",
            "Number of ham messages in data set: 4825\n",
            "Number of spam messages in data set: 747\n",
            "Shape of feature matrix: (5572, 8536)\n",
            "Training set shape: (4457, 8536)\n",
            "Test set shape: (1115, 8536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BTYNwcyZFZKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVC (replacing KNN)\n",
        "from sklearn.svm import LinearSVC\n",
        "svc = LinearSVC(C=0.1, class_weight='balanced', max_iter=10000)  # Regularized with C=0.1\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = svc.predict(X_train)\n",
        "y_test_pred = svc.predict(X_test)\n",
        "\n",
        "svc_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "svc_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
        "svc_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "svc_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "svc_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "svc_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print('SVC Model performance for Training set')\n",
        "print('- Accuracy: %s' % svc_train_accuracy)\n",
        "print('- MCC: %s' % svc_train_mcc)\n",
        "print('- F1 score: %s' % svc_train_f1)\n",
        "print('----------------------------------')\n",
        "print('SVC Model performance for Test set')\n",
        "print('- Accuracy: %s' % svc_test_accuracy)\n",
        "print('- MCC: %s' % svc_test_mcc)\n",
        "print('- F1 score: %s' % svc_test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlKmLF5x7-NU",
        "outputId": "c246fb15-e5d3-4e1a-d327-da6e22542d24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Model performance for Training set\n",
            "- Accuracy: 0.9910253533767108\n",
            "- MCC: 0.9624602343369298\n",
            "- F1 score: 0.9911116658050965\n",
            "----------------------------------\n",
            "SVC Model performance for Test set\n",
            "- Accuracy: 0.9766816143497757\n",
            "- MCC: 0.8978004830009131\n",
            "- F1 score: 0.9764781384666793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZY_NPI9FePv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree (already constrained)\n",
        "dt = DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = dt.predict(X_train)\n",
        "y_test_pred = dt.predict(X_test)\n",
        "\n",
        "dt_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "dt_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
        "dt_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "dt_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "dt_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "dt_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print('DT Model performance for Training set')\n",
        "print('- Accuracy: %s' % dt_train_accuracy)\n",
        "print('- MCC: %s' % dt_train_mcc)\n",
        "print('- F1 score: %s' % dt_train_f1)\n",
        "print('----------------------------------')\n",
        "print('DT Model performance for Test set')\n",
        "print('- Accuracy: %s' % dt_test_accuracy)\n",
        "print('- MCC: %s' % dt_test_mcc)\n",
        "print('- F1 score: %s' % dt_test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY1qAsmu2oAb",
        "outputId": "d40ca326-beb2-414c-df77-0f628a1336b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT Model performance for Training set\n",
            "- Accuracy: 0.9450302894323536\n",
            "- MCC: 0.7684464116954787\n",
            "- F1 score: 0.9455772888332558\n",
            "----------------------------------\n",
            "DT Model performance for Test set\n",
            "- Accuracy: 0.9488789237668162\n",
            "- MCC: 0.7837994593142213\n",
            "- F1 score: 0.9493726116565195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7jtA2BUFkQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest (relaxed regularization)\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=50,  # Increased from 30\n",
        "    max_depth=30,     # Increased from 20\n",
        "    min_samples_split=5,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = rf.predict(X_train)\n",
        "y_test_pred = rf.predict(X_test)\n",
        "\n",
        "rf_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "rf_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
        "rf_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "rf_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "rf_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "rf_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print('RF Model performance for Training set')\n",
        "print('- Accuracy: %s' % rf_train_accuracy)\n",
        "print('- MCC: %s' % rf_train_mcc)\n",
        "print('- F1 score: %s' % rf_train_f1)\n",
        "print('----------------------------------')\n",
        "print('RF Model performance for Test set')\n",
        "print('- Accuracy: %s' % rf_test_accuracy)\n",
        "print('- MCC: %s' % rf_test_mcc)\n",
        "print('- F1 score: %s' % rf_test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVVfzocy8PDL",
        "outputId": "a461698a-7aed-43d7-d20d-7bf534c7072f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Model performance for Training set\n",
            "- Accuracy: 0.9894547902176352\n",
            "- MCC: 0.9540836834302537\n",
            "- F1 score: 0.9892792140048106\n",
            "----------------------------------\n",
            "RF Model performance for Test set\n",
            "- Accuracy: 0.9820627802690582\n",
            "- MCC: 0.9208523277239943\n",
            "- F1 score: 0.9815690139456956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network (MLP, with dropout to reduce overfitting)\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(50,),\n",
        "    alpha=0.5,  # Increased from 0.1\n",
        "    max_iter=1000,\n",
        "    learning_rate='adaptive',\n",
        "    random_state=42,\n",
        "    early_stopping=True,  # Added to prevent overfitting\n",
        "    validation_fraction=0.1\n",
        ")\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = mlp.predict(X_train)\n",
        "y_test_pred = mlp.predict(X_test)\n",
        "\n",
        "mlp_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "mlp_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
        "mlp_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "mlp_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "mlp_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "mlp_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print('MLP Model performance for Training set')\n",
        "print('- Accuracy: %s' % mlp_train_accuracy)\n",
        "print('- MCC: %s' % mlp_train_mcc)\n",
        "print('- F1 score: %s' % mlp_train_f1)\n",
        "print('----------------------------------')\n",
        "print('MLP Model performance for Test set')\n",
        "print('- Accuracy: %s' % mlp_test_accuracy)\n",
        "print('- MCC: %s' % mlp_test_mcc)\n",
        "print('- F1 score: %s' % mlp_test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8_LBcnbFn_l",
        "outputId": "4cea85f3-eddf-47a3-c780-bc59dbc669da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model performance for Training set\n",
            "- Accuracy: 0.9721785954678035\n",
            "- MCC: 0.8760669171000149\n",
            "- F1 score: 0.97091543728438\n",
            "----------------------------------\n",
            "MLP Model performance for Test set\n",
            "- Accuracy: 0.9614349775784753\n",
            "- MCC: 0.8245458936830266\n",
            "- F1 score: 0.959063784276791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkGAz4-2FqrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost with expanded regularization\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_weight=5,  # Added to reduce overfitting\n",
        "    gamma=1,             # Added for regularization\n",
        "    scale_pos_weight=4825/747,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = xgb_clf.predict(X_train)\n",
        "y_test_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "xgb_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "xgb_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
        "xgb_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "xgb_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "xgb_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "xgb_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print('XGBoost Model performance for Training set')\n",
        "print('- Accuracy: %s' % xgb_train_accuracy)\n",
        "print('- MCC: %s' % xgb_train_mcc)\n",
        "print('- F1 score: %s' % xgb_train_f1)\n",
        "print('----------------------------------')\n",
        "print('XGBoost Model performance for Test set')\n",
        "print('- Accuracy: %s' % xgb_test_accuracy)\n",
        "print('- MCC: %s' % xgb_test_mcc)\n",
        "print('- F1 score: %s' % xgb_test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wDuwGXB2upM",
        "outputId": "6c27f6b2-f78c-4c11-ef15-16c6e12b34c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:50:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model performance for Training set\n",
            "- Accuracy: 0.9831725375813327\n",
            "- MCC: 0.929674573327478\n",
            "- F1 score: 0.983362326276744\n",
            "----------------------------------\n",
            "XGBoost Model performance for Test set\n",
            "- Accuracy: 0.9748878923766816\n",
            "- MCC: 0.8904115205851921\n",
            "- F1 score: 0.9747430039725188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Classifier with calibration\n",
        "estimator_list = [\n",
        "    ('svc', svc),\n",
        "    ('dt', dt),\n",
        "    ('rf', rf),\n",
        "    ('mlp', mlp),\n",
        "    ('xgb', xgb_clf)\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimator_list,\n",
        "    final_estimator=LogisticRegression(C=0.5),  # Relaxed from 0.1\n",
        "    cv=5\n",
        ")\n",
        "stack_model = CalibratedClassifierCV(stack_model, cv=5, method='sigmoid')\n",
        "print(\"Training the stacked model with calibration...\")\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = stack_model.predict(X_train)\n",
        "y_test_pred = stack_model.predict(X_test)\n",
        "\n",
        "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
        "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print('Stacked Model performance for Training set')\n",
        "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
        "print('- MCC: %s' % stack_model_train_mcc)\n",
        "print('- F1 score: %s' % stack_model_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Stacked Model performance for Test set')\n",
        "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
        "print('- MCC: %s' % stack_model_test_mcc)\n",
        "print('- F1 score: %s' % stack_model_test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbujJ1dBFwf5",
        "outputId": "e9645dc7-75be-43c2-d5aa-30e1e4616fa8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the stacked model with calibration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:50:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:51:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:52:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:53:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:53:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:53:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:53:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:53:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:53:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacked Model performance for Training set\n",
            "- Accuracy: 0.9925959165357864\n",
            "- MCC: 0.9679962477095162\n",
            "- F1 score: 0.9925774761054852\n",
            "----------------------------------\n",
            "Stacked Model performance for Test set\n",
            "- Accuracy: 0.9829596412556054\n",
            "- MCC: 0.9248528519166247\n",
            "- F1 score: 0.9826279487090812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile results\n",
        "acc_train_list = {\n",
        "    'svc': svc_train_accuracy,\n",
        "    'dt': dt_train_accuracy,\n",
        "    'rf': rf_train_accuracy,\n",
        "    'mlp': mlp_train_accuracy,\n",
        "    'xgb': xgb_train_accuracy,\n",
        "    'stack': stack_model_train_accuracy\n",
        "}\n",
        "\n",
        "mcc_train_list = {\n",
        "    'svc': svc_train_mcc,\n",
        "    'dt': dt_train_mcc,\n",
        "    'rf': rf_train_mcc,\n",
        "    'mlp': mlp_train_mcc,\n",
        "    'xgb': xgb_train_mcc,\n",
        "    'stack': stack_model_train_mcc\n",
        "}\n",
        "\n",
        "f1_train_list = {\n",
        "    'svc': svc_train_f1,\n",
        "    'dt': dt_train_f1,\n",
        "    'rf': rf_train_f1,\n",
        "    'mlp': mlp_train_f1,\n",
        "    'xgb': xgb_train_f1,\n",
        "    'stack': stack_model_train_f1\n",
        "}\n",
        "\n",
        "acc_test_list = {\n",
        "    'svc': svc_test_accuracy,\n",
        "    'dt': dt_test_accuracy,\n",
        "    'rf': rf_test_accuracy,\n",
        "    'mlp': mlp_test_accuracy,\n",
        "    'xgb': xgb_test_accuracy,\n",
        "    'stack': stack_model_test_accuracy\n",
        "}\n",
        "\n",
        "mcc_test_list = {\n",
        "    'svc': svc_test_mcc,\n",
        "    'dt': dt_test_mcc,\n",
        "    'rf': rf_test_mcc,\n",
        "    'mlp': mlp_test_mcc,\n",
        "    'xgb': xgb_test_mcc,\n",
        "    'stack': stack_model_test_mcc\n",
        "}\n",
        "\n",
        "f1_test_list = {\n",
        "    'svc': svc_test_f1,\n",
        "    'dt': dt_test_f1,\n",
        "    'rf': rf_test_f1,\n",
        "    'mlp': mlp_test_f1,\n",
        "    'xgb': xgb_test_f1,\n",
        "    'stack': stack_model_test_f1\n",
        "}\n",
        "\n",
        "# Training results\n",
        "acc_df = pd.DataFrame.from_dict(acc_train_list, orient='index', columns=['Accuracy'])\n",
        "mcc_df = pd.DataFrame.from_dict(mcc_train_list, orient='index', columns=['MCC'])\n",
        "f1_df = pd.DataFrame.from_dict(f1_train_list, orient='index', columns=['F1'])\n",
        "train_df = pd.concat([acc_df, mcc_df, f1_df], axis=1)\n",
        "print(\"Training Results:\\n\", train_df)\n",
        "\n",
        "# Test results\n",
        "acc_test_df = pd.DataFrame.from_dict(acc_test_list, orient='index', columns=['Accuracy'])\n",
        "mcc_test_df = pd.DataFrame.from_dict(mcc_test_list, orient='index', columns=['MCC'])\n",
        "f1_test_df = pd.DataFrame.from_dict(f1_test_list, orient='index', columns=['F1'])\n",
        "test_df = pd.concat([acc_test_df, mcc_test_df, f1_test_df], axis=1)\n",
        "print(\"Test Results:\\n\", test_df)\n",
        "\n",
        "# Save results locally\n",
        "train_df.to_csv('/content/train_results_final_balanced.csv')\n",
        "test_df.to_csv('/content/test_results_final_balanced.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSRdebg2F6Hv",
        "outputId": "ac8cb68c-d184-4609-aac7-6b26f34c9bf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "        Accuracy       MCC        F1\n",
            "svc    0.991025  0.962460  0.991112\n",
            "dt     0.945030  0.768446  0.945577\n",
            "rf     0.989455  0.954084  0.989279\n",
            "mlp    0.972179  0.876067  0.970915\n",
            "xgb    0.983173  0.929675  0.983362\n",
            "stack  0.992596  0.967996  0.992577\n",
            "Test Results:\n",
            "        Accuracy       MCC        F1\n",
            "svc    0.976682  0.897800  0.976478\n",
            "dt     0.948879  0.783799  0.949373\n",
            "rf     0.982063  0.920852  0.981569\n",
            "mlp    0.961435  0.824546  0.959064\n",
            "xgb    0.974888  0.890412  0.974743\n",
            "stack  0.982960  0.924853  0.982628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the stacked model locally\n",
        "joblib.dump(stack_model, '/content/stack_final_balanced.sav')\n",
        "\n",
        "# Load and predict\n",
        "loaded_model = joblib.load('/content/stack_final_balanced.sav')\n",
        "A = vectorizer.transform(data.Text)\n",
        "dd = loaded_model.predict(A)\n",
        "tac = dd[14:20]\n",
        "p = 10\n",
        "\n",
        "for i in tac:\n",
        "    if i == 1:\n",
        "        print(\"Spam message:\", data['Text'][p], \"\\n\")\n",
        "    else:\n",
        "        print(\"Legitimate message:\", data['Text'][p], \"\\n\")\n",
        "    p += 1\n",
        "\n",
        "# Download results and model\n",
        "from google.colab import files\n",
        "#files.download('/content/train_results_final_balanced.csv')\n",
        "#files.download('/content/test_results_final_balanced.csv')\n",
        "files.download('/content/stack_final_balanced.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "EUkEBALARg3E",
        "outputId": "e6ef7676-edbd-4289-ca56-8287aa3ecc5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legitimate message: I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today. \n",
            "\n",
            "Spam message: SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info \n",
            "\n",
            "Legitimate message: URGENT! You have won a 1 week FREE membership in our å£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18 \n",
            "\n",
            "Legitimate message: I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times. \n",
            "\n",
            "Legitimate message: I HAVE A DATE ON SUNDAY WITH WILL!! \n",
            "\n",
            "Spam message: XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a91295d8-ffe9-4af5-a251-3db480cc1318\", \"stack_final_balanced.sav\", 68435509)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv('1.csv', encoding='latin')\n",
        "data.rename(columns={'v1': 'Class', 'v2': 'Text'}, inplace=True)\n",
        "data['numClass'] = data['Class'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Vectorize text\n",
        "stopset = list(stopwords.words(\"english\"))\n",
        "vectorizer = TfidfVectorizer(stop_words=stopset)\n",
        "X = vectorizer.fit_transform(data.Text)\n",
        "y = data.numClass\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models (using your original parameters)\n",
        "svc = LinearSVC(C=0.1, class_weight='balanced', max_iter=10000)\n",
        "dt = DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
        "rf = RandomForestClassifier(n_estimators=50, max_depth=30, min_samples_split=5, class_weight='balanced')\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(50,), alpha=0.5, max_iter=1000, learning_rate='adaptive', random_state=42, early_stopping=True, validation_fraction=0.1)\n",
        "xgb_clf = xgb.XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, min_child_weight=5, gamma=1, scale_pos_weight=4825/747, random_state=42, eval_metric='logloss')\n",
        "\n",
        "# Train base models\n",
        "svc.fit(X_train, y_train)\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "mlp.fit(X_train, y_train)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Define and train stacking model\n",
        "estimator_list = [('svc', svc), ('dt', dt), ('rf', rf), ('mlp', mlp), ('xgb', xgb_clf)]\n",
        "stack_model = StackingClassifier(estimators=estimator_list, final_estimator=LogisticRegression(C=0.5), cv=5)\n",
        "stack_model = CalibratedClassifierCV(stack_model, cv=5, method='sigmoid')\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model and vectorizer\n",
        "joblib.dump(stack_model, '/content/stack_final_balanced.sav')\n",
        "joblib.dump(vectorizer, '/content/vectorizer.sav')  # Save vectorizer for future use\n",
        "\n",
        "print(\"Model and vectorizer saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3JIjIyjLujx",
        "outputId": "f17998df-5274-412e-9af5-54cb67dd8145"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and vectorizer saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "loaded_model = joblib.load('/content/stack_final_balanced.sav')\n",
        "vectorizer = joblib.load('/content/vectorizer.sav')  # Load the saved vectorizer\n",
        "\n",
        "# Custom statement\n",
        "custom_statement = \"hello world\"\n",
        "\n",
        "# Transform and predict\n",
        "custom_transformed = vectorizer.transform([custom_statement])\n",
        "prediction = loaded_model.predict(custom_transformed)\n",
        "\n",
        "# Output result\n",
        "if prediction[0] == 1:\n",
        "    print(f\"Prediction for '{custom_statement}': Spam\")\n",
        "else:\n",
        "    print(f\"Prediction for '{custom_statement}': Legitimate (Ham)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gglfVuWPQQY8",
        "outputId": "ddfb2823-39b0-4b4b-a243-e219352ea3e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for 'hello world': Legitimate (Ham)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "loaded_model = joblib.load('/content/stack_final_balanced.sav')\n",
        "vectorizer = joblib.load('/content/vectorizer.sav')  # Assuming you saved it during training\n",
        "\n",
        "# Get user input\n",
        "custom_statement = input(\"Enter a message to classify (e.g., 'Win a free iPhone now!'): \")\n",
        "\n",
        "# Transform the user input using the loaded vectorizer\n",
        "custom_transformed = vectorizer.transform([custom_statement])\n",
        "\n",
        "# Predict using the loaded model\n",
        "prediction = loaded_model.predict(custom_transformed)\n",
        "\n",
        "# Interpret and display the result\n",
        "if prediction[0] == 1:\n",
        "    print(f\"Prediction for '{custom_statement}': Spam\")\n",
        "else:\n",
        "    print(f\"Prediction for '{custom_statement}': Legitimate (Ham)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egdnigGdRM2H",
        "outputId": "e027d24c-3a57-4f0b-8ce7-55197268584f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a message to classify (e.g., 'Win a free iPhone now!'): 'Win a free iPhone now!\n",
            "Prediction for ''Win a free iPhone now!': Spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_8wpeoomKhL7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}